{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import FrEIA.framework as Ff\n",
    "import FrEIA.modules as Fm\n",
    "import matplotlib\n",
    "\n",
    "from helpers import *\n",
    "from os.path import exists\n",
    "from argparse import ArgumentParser\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "plt.rcParams.update({'axes.labelsize': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--test'], dest='test', nargs=None, const=None, default=0, type=<class 'int'>, choices=None, help='Test run {True, False}', metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = ArgumentParser()\n",
    "parser.add_argument(\"-c\", \"--cuda\", dest=\"cuda\", default=2, type=int, help='Cuda number')\n",
    "\n",
    "parser.add_argument(\"-f\", '--flows', dest=\"flows\", default=8, type=int, help='Number of flows')\n",
    "parser.add_argument(\"--nn-hidden\", dest=\"nn_hidden\", default=3, type=int, help='Number of hidden layers for the NN')\n",
    "parser.add_argument(\"--nn-nodes\", dest=\"nn_nodes\", default=200, type=int, help='Number of hidden nodes for NN')\n",
    "parser.add_argument(\"--model\", dest=\"model\", default='8flows_3layer_200nodes_50000batch/model.pt', type=str, help='Path to model')\n",
    "parser.add_argument(\"--output\", dest=\"output\", default='flow_nnensemble_dummy/', type=str, help='Path for output files')\n",
    "\n",
    "parser.add_argument(\"--test\", dest=\"test\", default=0, type=int, help='Test run {True, False}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(cuda=2, flows=8, model='8flows_3layer_200nodes_50000batch/model.pt', nn_hidden=3, nn_nodes=200, output='flow_nnensemble_dummy/', test=0)\n"
     ]
    }
   ],
   "source": [
    "# pass default arguments if executed as ipynb\n",
    "try: \n",
    "    if get_ipython().__class__.__name__ == 'ZMQInteractiveShell': args = parser.parse_args(\"\") \n",
    "except:\n",
    "    args = parser.parse_args()\n",
    "\n",
    "device = torch.device(args.cuda)\n",
    "print(args)\n",
    "ensure_dir(args.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = ['metphi','pt_vis_c', 'phi_vis_c','pt_1', 'pt_2','dxy_1', 'dxy_2','dz_1',\n",
    "        'dz_2','eta_1', 'eta_2','mass_1', 'mass_2','metSumEt']\n",
    "names = ['uP1_uncorrected', 'uP2_uncorrected']\n",
    "paths = os.listdir('ensemble/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files from:  /ceph/lsowa/recoil/dt.root\n",
      "No.  1\n",
      "No.  2\n",
      "No.  3\n",
      "No.  4\n",
      "No.  5\n",
      "Reading files from:  /ceph/lsowa/recoil/mc.root\n",
      "No.  1\n",
      "No.  2\n",
      "No.  3\n",
      "No.  4\n",
      "No.  5\n",
      "No.  6\n",
      "No.  7\n"
     ]
    }
   ],
   "source": [
    "if exists('/ceph/lsowa/recoil/dt.root'):\n",
    "    dfdata = load_from_root('/ceph/lsowa/recoil/dt.root', test=args.test)\n",
    "    dfmc = load_from_root('/ceph/lsowa/recoil/mc.root', test=args.test)\n",
    "else:\n",
    "    # when running on cluster\n",
    "    dfdata = load_from_root('recoil/dt.root', test=args.test)\n",
    "    dfmc = load_from_root('recoil/mc.root', test=args.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dfdata[names].to_numpy().astype(float)\n",
    "mc = dfmc[names].to_numpy().astype(float)\n",
    "cdata = dfdata[cond].to_numpy().astype(float)\n",
    "cmc = dfmc[cond].to_numpy().astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +\n",
    "# Z standardize inputs\n",
    "# +\n",
    "input_scaler = StandardScaler()\n",
    "data = input_scaler.fit_transform(data)\n",
    "mc = input_scaler.transform(mc)\n",
    "\n",
    "cond_scaler = StandardScaler()\n",
    "cdata = cond_scaler.fit_transform(cdata)\n",
    "cmc = cond_scaler.transform(cmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, mc, cdata, cmc = torch.tensor(data), torch.tensor(mc), torch.tensor(cdata), torch.tensor(cmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pz = dist.MultivariateNormal(torch.zeros(2), torch.eye(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Load models\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlps\n",
    "mlps = []\n",
    "for path in paths:\n",
    "    with torch.no_grad():\n",
    "        mlp = Mlp(input_neurons=cdata.shape[1], hidden_neurons=200, output_neurons=2, hiddenlayers=3)\n",
    "        path = 'ensemble/' + path + '/model.pt'\n",
    "        mlp.load_state_dict(torch.load(path, map_location=\"cpu\"))\n",
    "        mlps.append(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flows\n",
    "def mlp_constructor(input_dim=2, out_dim=2, hidden_nodes=args.nn_nodes):\n",
    "    \n",
    "    layers = [nn.Linear(input_dim, hidden_nodes), nn.ReLU()]\n",
    "    for n in range(args.nn_hidden-1):\n",
    "        layers.append(nn.Linear(hidden_nodes, hidden_nodes))\n",
    "        layers.append(nn.ReLU())\n",
    "    layers.append(nn.Linear(hidden_nodes, out_dim))\n",
    "    \n",
    "    model = nn.Sequential(*layers)\n",
    "    return model\n",
    "\n",
    "model = Ff.SequenceINN(2)\n",
    "for k in range(args.flows):\n",
    "    model.append(Fm.RNVPCouplingBlock, subnet_constructor=mlp_constructor, \n",
    "                    clamp=2, cond=0, cond_shape=(cmc.shape[1],))\n",
    "\n",
    "model.load_state_dict(torch.load(args.model, map_location=\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# one event multiple times\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 5000\n",
      "Batch size: 5000\n",
      "Batch size: 5000\n",
      "Batch size: 5000\n"
     ]
    }
   ],
   "source": [
    "for event in range(100, 111):\n",
    "    csingle_event = cmc[event,:].unsqueeze(0)\n",
    "    csingle_events = torch.concat([csingle_event]*10000)\n",
    "\n",
    "    model.cpu()\n",
    "    z = pz.sample((csingle_events.shape[0], ))\n",
    "    u, jac = evaluate_sequential(model, z, cond=csingle_events.float(), rev=True)\n",
    "    u = input_scaler.inverse_transform(u)\n",
    "\n",
    "    u_mlps = []\n",
    "    for mlp in mlps:\n",
    "        with torch.no_grad():\n",
    "            out = mlp(csingle_event.float())\n",
    "            u_mlps.append(out)\n",
    "    u_mlps = torch.concat(u_mlps)\n",
    "    u_mlps = input_scaler.inverse_transform(u_mlps.numpy())\n",
    "\n",
    "    density_2d(u, u_mlps, \n",
    "        line_label=r'NN Ensemble NN($\\mathrm{cond}_\\mathrm{MC}$)=$\\vec{u}$', hist_label=r'model(z, $\\mathrm{cond}_\\mathrm{MC}$)=$\\vec{u}$',\n",
    "        crosses = [dfmc[\"uP1_uncorrected\"][event], dfmc[\"uP2_uncorrected\"][event]], crosses_label=r'$\\vec{u}^\\mathrm{truth}_\\mathrm{MC}$',\n",
    "        xlim = [-160, 100], ylim = [-80, 30], save_as=args.output+'fixedevent_flows_mlpensemble_eventid'+ str(event) +'.pdf', gridsize=(50,50), bins=100,\n",
    "        hist_mean_label='model mean', hist_mode_label='model mode', grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# compare MLP ensemble with multiple evaluated NFlow\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptz = dfmc['pt_vis_c']\n",
    "cmc = cmc.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-22dde623979f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# keep u_perp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mhist_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist_weighted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbin_mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muperp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mptz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mptz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcut_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcut_min\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhist_weighted\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mhist_raw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/lsowa/recoil_correction/helpers.py\u001b[0m in \u001b[0;36mcalc_response\u001b[0;34m(uperp, ptz, cut_max, cut_min)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0mkeep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcut_max\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mptz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mptz\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mcut_min\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0mptz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mptz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0muperp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muperp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0muperp\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mptz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ceph/lsowa/envs/cluster/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Evaluate Mlp ensemble\n",
    "rs = []\n",
    "for mlp in mlps:\n",
    "    with torch.no_grad():\n",
    "        mlp.to(device)\n",
    "        out = mlp(cmc.float())\n",
    "        out = input_scaler.inverse_transform(out.cpu().numpy())\n",
    "        out = torch.tensor(out[:,0]) # keep u_perp\n",
    "        mlp.cpu()\n",
    "    hist_raw, hist_weighted, bins, bin_mids = calc_response(uperp=out, ptz=ptz, cut_max=200, cut_min=25)\n",
    "    r = hist_weighted/hist_raw\n",
    "    rs.append(r)\n",
    "rs = np.array(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_downs, mlp_ups = np.percentile(rs, q=[5, 95], axis=0)\n",
    "mlp_means = np.mean(rs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate NFlow multiple times\n",
    "cmc = cmc.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Batch size: 1000000\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([1000000, 2])\n",
      "torch.Size([780880, 2])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ptz' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-ba59ff7377ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mu_flow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_flow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mhist_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist_weighted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbin_mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muperp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mu_flow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mptz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mptz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcut_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcut_min\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhist_weighted\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mhist_raw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mrs_flow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ptz' is not defined"
     ]
    }
   ],
   "source": [
    "pz = dist.MultivariateNormal(torch.zeros(2), torch.eye(2))\n",
    "rs_flow = []\n",
    "flow_evaluations = 20\n",
    "for i in range(len(mlps)):\n",
    "    print(i)\n",
    "    z = pz.sample((cmc.shape[0]*flow_evaluations, ))\n",
    "    u_flow, _ = evaluate_sequential(model, z, cond=torch.vstack([cmc]*flow_evaluations).float(), \n",
    "                                    rev=True, device=device, batch=1000000)\n",
    "    u_flow = u_flow.view(flow_evaluations, cmc.shape[0], u_flow.shape[1])\n",
    "    u_flow = u_flow.mean(dim=0)\n",
    "    \n",
    "    u_flow = input_scaler.inverse_transform(u_flow.cpu().numpy())\n",
    "    hist_raw, hist_weighted, bins, bin_mids = calc_response(uperp=u_flow[:,0], ptz=ptz, cut_max=200, cut_min=25)\n",
    "    r = hist_weighted/hist_raw\n",
    "    rs_flow.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_downs, flow_ups = np.percentile(rs_flow, q=[5, 95], axis=0)\n",
    "flow_means = np.mean(rs_flow, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "plt.errorbar(x=bin_mids, y=mlp_means,\n",
    "            xerr=(bins[1:]-bins[:-1])/2, yerr=[mlp_means-mlp_downs, mlp_ups-mlp_means], fmt='o', capsize=2, label='MLP Ensemble 90% Conf. Int.')\n",
    "plt.errorbar(x=bin_mids, y=flow_means,\n",
    "            xerr=(bins[1:]-bins[:-1])/2, yerr=[flow_means-flow_downs, flow_ups-flow_means], fmt='o', capsize=2, label='Averaged Flow 90% Conf. Int.')\n",
    "\n",
    "plt.hlines([1], bins.min(), bins.max(), color='black')\n",
    "plt.xlabel(r'$p_\\mathrm{T}^Z$ in GeV')\n",
    "plt.ylabel(r'$\\langle \\frac{\\mathrm{u}_\\parallel}{p_\\mathrm{T}^Z}\\rangle$')\n",
    "plt.xlim([bins.min(), bins.max()])\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(args.output + 'response_compare_new.pdf')\n",
    "plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "cluster",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "b005ab6eda12d21ebceb8ef5791a16fc55b2ce86fd289021a8c5462e4b8c3e2c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
