{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import FrEIA.framework as Ff\n",
    "import FrEIA.modules as Fm\n",
    "import matplotlib\n",
    "\n",
    "from helpers import *\n",
    "from os.path import exists\n",
    "from argparse import ArgumentParser\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--test'], dest='test', nargs=None, const=None, default=0, type=<class 'int'>, choices=None, help='Test run {True, False}', metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = ArgumentParser()\n",
    "parser.add_argument(\"-c\", \"--cuda\", dest=\"cuda\", default=1, type=int, help='Cuda number')\n",
    "\n",
    "parser.add_argument(\"-f\", '--flows', dest=\"flows\", default=8, type=int, help='Number of flows')\n",
    "parser.add_argument(\"--nn-hidden\", dest=\"nn_hidden\", default=3, type=int, help='Number of hidden layers for the NN')\n",
    "parser.add_argument(\"--nn-nodes\", dest=\"nn_nodes\", default=200, type=int, help='Number of hidden nodes for NN')\n",
    "parser.add_argument(\"--model\", dest=\"model\", default='8flows_3layer_200nodes_50000batch/model.pt', type=str, help='Path to model')\n",
    "parser.add_argument(\"--output\", dest=\"output\", default='flow_nnensemble_dummy/', type=str, help='Path for output files')\n",
    "\n",
    "parser.add_argument(\"--test\", dest=\"test\", default=0, type=int, help='Test run {True, False}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(cuda=1, flows=8, model='8flows_3layer_200nodes_50000batch/model.pt', nn_hidden=3, nn_nodes=200, output='flow_nnensemble_dummy/', test=0)\n"
     ]
    }
   ],
   "source": [
    "# pass default arguments if executed as ipynb\n",
    "try: \n",
    "    if get_ipython().__class__.__name__ == 'ZMQInteractiveShell': args = parser.parse_args(\"\") \n",
    "except:\n",
    "    args = parser.parse_args()\n",
    "\n",
    "device = torch.device(args.cuda)\n",
    "print(args)\n",
    "ensure_dir(args.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = ['metphi','pt_vis_c', 'phi_vis_c','pt_1', 'pt_2','dxy_1', 'dxy_2','dz_1',\n",
    "        'dz_2','eta_1', 'eta_2','mass_1', 'mass_2','metSumEt']\n",
    "names = ['uP1_uncorrected', 'uP2_uncorrected']\n",
    "paths = os.listdir('ensemble/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files from:  /ceph/lsowa/recoil/dt.root\n",
      "No.  1\n",
      "No.  2\n",
      "No.  3\n",
      "No.  4\n",
      "No.  5\n",
      "Reading files from:  /ceph/lsowa/recoil/mc.root\n",
      "No.  1\n",
      "No.  2\n",
      "No.  3\n",
      "No.  4\n",
      "No.  5\n",
      "No.  6\n",
      "No.  7\n"
     ]
    }
   ],
   "source": [
    "if exists('/ceph/lsowa/recoil/dt.root'):\n",
    "    dfdata = load_from_root('/ceph/lsowa/recoil/dt.root', test=args.test)\n",
    "    dfmc = load_from_root('/ceph/lsowa/recoil/mc.root', test=args.test)\n",
    "else:\n",
    "    # when running on cluster\n",
    "    dfdata = load_from_root('recoil/dt.root', test=args.test)\n",
    "    dfmc = load_from_root('recoil/mc.root', test=args.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dfdata[names].to_numpy().astype(float)\n",
    "mc = dfmc[names].to_numpy().astype(float)\n",
    "cdata = dfdata[cond].to_numpy().astype(float)\n",
    "cmc = dfmc[cond].to_numpy().astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +\n",
    "# Z standardize inputs\n",
    "# +\n",
    "input_scaler = StandardScaler()\n",
    "data = input_scaler.fit_transform(data)\n",
    "mc = input_scaler.transform(mc)\n",
    "\n",
    "cond_scaler = StandardScaler()\n",
    "cdata = cond_scaler.fit_transform(cdata)\n",
    "cmc = cond_scaler.transform(cmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, mc, cdata, cmc = torch.tensor(data), torch.tensor(mc), torch.tensor(cdata), torch.tensor(cmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pz = dist.MultivariateNormal(torch.zeros(2), torch.eye(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Load models\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlps\n",
    "mlps = []\n",
    "for path in paths:\n",
    "    with torch.no_grad():\n",
    "        mlp = Mlp(input_neurons=cdata.shape[1], hidden_neurons=200, output_neurons=2, hiddenlayers=3)\n",
    "        path = 'ensemble/' + path + '/model.pt'\n",
    "        mlp.load_state_dict(torch.load(path, map_location=\"cpu\"))\n",
    "        mlps.append(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flows\n",
    "def mlp_constructor(input_dim=2, out_dim=2, hidden_nodes=args.nn_nodes):\n",
    "    \n",
    "    layers = [nn.Linear(input_dim, hidden_nodes), nn.ReLU()]\n",
    "    for n in range(args.nn_hidden-1):\n",
    "        layers.append(nn.Linear(hidden_nodes, hidden_nodes))\n",
    "        layers.append(nn.ReLU())\n",
    "    layers.append(nn.Linear(hidden_nodes, out_dim))\n",
    "    \n",
    "    model = nn.Sequential(*layers)\n",
    "    return model\n",
    "\n",
    "model = Ff.SequenceINN(2)\n",
    "for k in range(args.flows):\n",
    "    model.append(Fm.RNVPCouplingBlock, subnet_constructor=mlp_constructor, \n",
    "                    clamp=2, cond=0, cond_shape=(cmc.shape[1],))\n",
    "\n",
    "model.load_state_dict(torch.load(args.model, map_location=\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# one event multiple times\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "csingle_event = cmc[100,:].unsqueeze(0)\n",
    "csingle_events = torch.concat([csingle_event]*10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceINN(\n",
       "  (module_list): ModuleList(\n",
       "    (0): RNVPCouplingBlock(\n",
       "      (subnet_s1): Sequential(\n",
       "        (0): Linear(in_features=15, out_features=200, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (5): ReLU()\n",
       "        (6): Linear(in_features=200, out_features=1, bias=True)\n",
       "      )\n",
       "      (subnet_t1): Sequential(\n",
       "        (0): Linear(in_features=15, out_features=200, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (5): ReLU()\n",
       "        (6): Linear(in_features=200, out_features=1, bias=True)\n",
       "      )\n",
       "      (subnet_s2): Sequential(\n",
       "        (0): Linear(in_features=15, out_features=200, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (5): ReLU()\n",
       "        (6): Linear(in_features=200, out_features=1, bias=True)\n",
       "      )\n",
       "      (subnet_t2): Sequential(\n",
       "        (0): Linear(in_features=15, out_features=200, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (5): ReLU()\n",
       "        (6): Linear(in_features=200, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (1): RNVPCouplingBlock(\n",
       "      (subnet_s1): Sequential(\n",
       "        (0): Linear(in_features=15, out_features=200, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (5): ReLU()\n",
       "        (6): Linear(in_features=200, out_features=1, bias=True)\n",
       "      )\n",
       "      (subnet_t1): Sequential(\n",
       "        (0): Linear(in_features=15, out_features=200, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (5): ReLU()\n",
       "        (6): Linear(in_features=200, out_features=1, bias=True)\n",
       "      )\n",
       "      (subnet_s2): Sequential(\n",
       "        (0): Linear(in_features=15, out_features=200, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (5): ReLU()\n",
       "        (6): Linear(in_features=200, out_features=1, bias=True)\n",
       "      )\n",
       "      (subnet_t2): Sequential(\n",
       "        (0): Linear(in_features=15, out_features=200, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (5): ReLU()\n",
       "        (6): Linear(in_features=200, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (2): RNVPCouplingBlock(\n",
       "      (subnet_s1): Sequential(\n",
       "        (0): Linear(in_features=15, out_features=200, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (5): ReLU()\n",
       "        (6): Linear(in_features=200, out_features=1, bias=True)\n",
       "      )\n",
       "      (subnet_t1): Sequential(\n",
       "        (0): Linear(in_features=15, out_features=200, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (5): ReLU()\n",
       "        (6): Linear(in_features=200, out_features=1, bias=True)\n",
       "      )\n",
       "      (subnet_s2): Sequential(\n",
       "        (0): Linear(in_features=15, out_features=200, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (5): ReLU()\n",
       "        (6): Linear(in_features=200, out_features=1, bias=True)\n",
       "      )\n",
       "      (subnet_t2): Sequential(\n",
       "        (0): Linear(in_features=15, out_features=200, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (5): ReLU()\n",
       "        (6): Linear(in_features=200, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (3): RNVPCouplingBlock(\n",
       "      (subnet_s1): Sequential(\n",
       "        (0): Linear(in_features=15, out_features=200, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (5): ReLU()\n",
       "        (6): Linear(in_features=200, out_features=1, bias=True)\n",
       "      )\n",
       "      (subnet_t1): Sequential(\n",
       "        (0): Linear(in_features=15, out_features=200, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (5): ReLU()\n",
       "        (6): Linear(in_features=200, out_features=1, bias=True)\n",
       "      )\n",
       "      (subnet_s2): Sequential(\n",
       "        (0): Linear(in_features=15, out_features=200, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (5): ReLU()\n",
       "        (6): Linear(in_features=200, out_features=1, bias=True)\n",
       "      )\n",
       "      (subnet_t2): Sequential(\n",
       "        (0): Linear(in_features=15, out_features=200, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (5): ReLU()\n",
       "        (6): Linear(in_features=200, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (4): RNVPCouplingBlock(\n",
       "      (subnet_s1): Sequential(\n",
       "        (0): Linear(in_features=15, out_features=200, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (5): ReLU()\n",
       "        (6): Linear(in_features=200, out_features=1, bias=True)\n",
       "      )\n",
       "      (subnet_t1): Sequential(\n",
       "        (0): Linear(in_features=15, out_features=200, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (5): ReLU()\n",
       "        (6): Linear(in_features=200, out_features=1, bias=True)\n",
       "      )\n",
       "      (subnet_s2): Sequential(\n",
       "        (0): Linear(in_features=15, out_features=200, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (5): ReLU()\n",
       "        (6): Linear(in_features=200, out_features=1, bias=True)\n",
       "      )\n",
       "      (subnet_t2): Sequential(\n",
       "        (0): Linear(in_features=15, out_features=200, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (5): ReLU()\n",
       "        (6): Linear(in_features=200, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (5): RNVPCouplingBlock(\n",
       "      (subnet_s1): Sequential(\n",
       "        (0): Linear(in_features=15, out_features=200, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (5): ReLU()\n",
       "        (6): Linear(in_features=200, out_features=1, bias=True)\n",
       "      )\n",
       "      (subnet_t1): Sequential(\n",
       "        (0): Linear(in_features=15, out_features=200, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (5): ReLU()\n",
       "        (6): Linear(in_features=200, out_features=1, bias=True)\n",
       "      )\n",
       "      (subnet_s2): Sequential(\n",
       "        (0): Linear(in_features=15, out_features=200, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (5): ReLU()\n",
       "        (6): Linear(in_features=200, out_features=1, bias=True)\n",
       "      )\n",
       "      (subnet_t2): Sequential(\n",
       "        (0): Linear(in_features=15, out_features=200, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (5): ReLU()\n",
       "        (6): Linear(in_features=200, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (6): RNVPCouplingBlock(\n",
       "      (subnet_s1): Sequential(\n",
       "        (0): Linear(in_features=15, out_features=200, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (5): ReLU()\n",
       "        (6): Linear(in_features=200, out_features=1, bias=True)\n",
       "      )\n",
       "      (subnet_t1): Sequential(\n",
       "        (0): Linear(in_features=15, out_features=200, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (5): ReLU()\n",
       "        (6): Linear(in_features=200, out_features=1, bias=True)\n",
       "      )\n",
       "      (subnet_s2): Sequential(\n",
       "        (0): Linear(in_features=15, out_features=200, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (5): ReLU()\n",
       "        (6): Linear(in_features=200, out_features=1, bias=True)\n",
       "      )\n",
       "      (subnet_t2): Sequential(\n",
       "        (0): Linear(in_features=15, out_features=200, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (5): ReLU()\n",
       "        (6): Linear(in_features=200, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (7): RNVPCouplingBlock(\n",
       "      (subnet_s1): Sequential(\n",
       "        (0): Linear(in_features=15, out_features=200, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (5): ReLU()\n",
       "        (6): Linear(in_features=200, out_features=1, bias=True)\n",
       "      )\n",
       "      (subnet_t1): Sequential(\n",
       "        (0): Linear(in_features=15, out_features=200, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (5): ReLU()\n",
       "        (6): Linear(in_features=200, out_features=1, bias=True)\n",
       "      )\n",
       "      (subnet_s2): Sequential(\n",
       "        (0): Linear(in_features=15, out_features=200, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (5): ReLU()\n",
       "        (6): Linear(in_features=200, out_features=1, bias=True)\n",
       "      )\n",
       "      (subnet_t2): Sequential(\n",
       "        (0): Linear(in_features=15, out_features=200, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (5): ReLU()\n",
       "        (6): Linear(in_features=200, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = pz.sample((csingle_events.shape[0], ))\n",
    "u, _ = evaluate_sequential(model, z, cond=csingle_events.float(), rev=True)\n",
    "\n",
    "u = input_scaler.inverse_transform(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_mlps = []\n",
    "for mlp in mlps:\n",
    "    with torch.no_grad():\n",
    "        out = mlp(csingle_event.float())\n",
    "        u_mlps.append(out)\n",
    "u_mlps = torch.concat(u_mlps)\n",
    "u_mlps = input_scaler.inverse_transform(u_mlps.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "density_2d(u, u_mlps, \n",
    "            line_label=r'NN Ensamble NN(cond)$', hist_label=r'model(z, $\\mathrm{cond}^\\mathrm{fixed}_\\mathrm{MC}$)=$\\hat{y}$', \n",
    "            xlim = [-160, 100], ylim = [-80, 30], save_as=args.output+'fixedevent_flows_mlpensemble.pdf', gridsize=(50,50), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# compare MLP ensemble with multiple evaluated NFlow\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptz = dfmc['pt_vis_c']\n",
    "cmc = cmc.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-22dde623979f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# keep u_perp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mhist_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist_weighted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbin_mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muperp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mptz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mptz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcut_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcut_min\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhist_weighted\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mhist_raw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/lsowa/recoil_correction/helpers.py\u001b[0m in \u001b[0;36mcalc_response\u001b[0;34m(uperp, ptz, cut_max, cut_min)\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0mkeep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcut_max\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mptz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mptz\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mcut_min\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0mptz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mptz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m     \u001b[0muperp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muperp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0muperp\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mptz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ceph/lsowa/envs/cluster/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpack_1tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_fallback_to_positional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    879\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ceph/lsowa/envs/cluster/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_should_fallback_to_positional\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4620\u001b[0m         \u001b[0mShould\u001b[0m \u001b[0man\u001b[0m \u001b[0minteger\u001b[0m \u001b[0mkey\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mtreated\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;31m?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4621\u001b[0m         \"\"\"\n\u001b[0;32m-> 4622\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4623\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4624\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ceph/lsowa/envs/cluster/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mholds_integer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1996\u001b[0m         \u001b[0mWhether\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0man\u001b[0m \u001b[0minteger\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m         \"\"\"\n\u001b[0;32m-> 1998\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minferred_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"integer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mixed-integer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2000\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ceph/lsowa/envs/cluster/lib/python3.6/site-packages/pandas/core/indexes/numeric.py\u001b[0m in \u001b[0;36minferred_type\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minferred_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \"\"\"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Evaluate Mlp ensemble\n",
    "rs = []\n",
    "for mlp in mlps:\n",
    "    with torch.no_grad():\n",
    "        mlp.to(device)\n",
    "        out = mlp(cmc.float())\n",
    "        out = input_scaler.inverse_transform(out.cpu().numpy())\n",
    "        out = torch.tensor(out[:,0]) # keep u_perp\n",
    "    hist_raw, hist_weighted, bins, bin_mids = calc_response(uperp=out, ptz=ptz, cut_max=200, cut_min=25)\n",
    "    r = hist_weighted/hist_raw\n",
    "    rs.append(r)\n",
    "rs = np.array(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_downs, mlp_ups = np.percentile(rs, q=[2.5, 97.5], axis=0)\n",
    "mlp_means = np.mean(rs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate NFlow multiple times\n",
    "cmc = cmc.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f1612b1ba90>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/ceph/lsowa/envs/cluster/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f1612b1ba90>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/ceph/lsowa/envs/cluster/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f1612b1ba90>>\n",
      "Traceback (most recent call last):\n",
      "          File \"/ceph/lsowa/envs/cluster/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "self._shutdown_workers()self._shutdown_workers()\n",
      "\n",
      "  File \"/ceph/lsowa/envs/cluster/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "  File \"/ceph/lsowa/envs/cluster/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    self._shutdown_workers()\n",
      "          File \"/ceph/lsowa/envs/cluster/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "if w.is_alive():if w.is_alive():\n",
      "\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 134, in is_alive\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 134, in is_alive\n",
      "            if w.is_alive():assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 134, in is_alive\n",
      "AssertionErrorAssertionError:     : can only test a child processcan only test a child processassert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f1612b1ba90>>\n",
      "Exception ignored in: Traceback (most recent call last):\n",
      "  File \"/ceph/lsowa/envs/cluster/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "<bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f1612b1ba90>><bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f1612b1ba90>>\n",
      "Exception ignored in: \n",
      "Traceback (most recent call last):\n",
      "  File \"/ceph/lsowa/envs/cluster/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "Traceback (most recent call last):\n",
      "  File \"/ceph/lsowa/envs/cluster/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "        self._shutdown_workers()    self._shutdown_workers()self._shutdown_workers()\n",
      "\n",
      "\n",
      "  File \"/ceph/lsowa/envs/cluster/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "  File \"/ceph/lsowa/envs/cluster/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "  File \"/ceph/lsowa/envs/cluster/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "            if w.is_alive():if w.is_alive():if w.is_alive():\n",
      "\n",
      "\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 134, in is_alive\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 134, in is_alive\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 134, in is_alive\n",
      "            assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "\n",
      "AssertionErrorAssertionErrorAssertionError: : can only test a child process: can only test a child process\n",
      "\n",
      "can only test a child process\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-4fe216e669a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mu_flow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_sequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mu_flow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_flow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mhist_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist_weighted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbin_mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muperp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mu_flow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mptz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mptz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcut_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcut_min\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/lsowa/recoil_correction/helpers.py\u001b[0m in \u001b[0;36mevaluate_sequential\u001b[0;34m(model, data, cond, device, batch, rev)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ceph/lsowa/envs/cluster/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ceph/lsowa/envs/cluster/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_worker_number_rationality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ceph/lsowa/envs/cluster/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_fork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mSpawnProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flush_std_streams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mparent_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pz = dist.MultivariateNormal(torch.zeros(2), torch.eye(2))\n",
    "rs_flow = []\n",
    "for i in range(len(mlps)):\n",
    "    z = pz.sample((cmc.shape[0], ))\n",
    "    u_flow, _ = evaluate_sequential(model, z, cond=cmc.float(), rev=True, device=device)\n",
    "    u_flow = input_scaler.inverse_transform(u_flow.cpu().numpy())\n",
    "    hist_raw, hist_weighted, bins, bin_mids = calc_response(uperp=u_flow[:,0], ptz=ptz, cut_max=200, cut_min=25)\n",
    "    r = hist_weighted/hist_raw\n",
    "    rs_flow.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_downs, flow_ups = np.percentile(rs_flow, q=[2.5, 97.5], axis=0)\n",
    "flow_means = np.mean(rs_flow, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mlp_means' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-b55fd5c148d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m plt.errorbar(x=bin_mids, y=mlp_means,\n\u001b[0m\u001b[1;32m      2\u001b[0m             xerr=(bins[1:]-bins[:-1])/2, yerr=[mlp_means-mlp_downs, mlp_ups-mlp_means], fmt='o', capsize=2, label='MLP Ensemble')\n\u001b[1;32m      3\u001b[0m plt.errorbar(x=bin_mids, y=flow_means,\n\u001b[1;32m      4\u001b[0m             xerr=(bins[1:]-bins[:-1])/2, yerr=[flow_means-flow_downs, flow_ups-flow_means], fmt='o', capsize=2, label='Flow')\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mlp_means' is not defined"
     ]
    }
   ],
   "source": [
    "plt.errorbar(x=bin_mids, y=mlp_means,\n",
    "            xerr=(bins[1:]-bins[:-1])/2, yerr=[mlp_means-mlp_downs, mlp_ups-mlp_means], fmt='o', capsize=2, label='MLP Ensemble')\n",
    "plt.errorbar(x=bin_mids, y=flow_means,\n",
    "            xerr=(bins[1:]-bins[:-1])/2, yerr=[flow_means-flow_downs, flow_ups-flow_means], fmt='o', capsize=2, label='Flow')\n",
    "\n",
    "plt.hlines([1], bins.min(), bins.max(), color='black')\n",
    "plt.xlabel(r'$p_\\mathrm{T}^Z$ in GeV')\n",
    "plt.ylabel(r'$\\langle \\frac{\\mathrm{u}_\\parallel}{p_\\mathrm{T}^Z}\\rangle$')\n",
    "plt.xlim([bins.min(), bins.max()])\n",
    "plt.legend()\n",
    "plt.savefig(args.output + 'response_compare.pdf')\n",
    "plt.clf()\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 ('cluster')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "b005ab6eda12d21ebceb8ef5791a16fc55b2ce86fd289021a8c5462e4b8c3e2c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
