{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import FrEIA.framework as Ff\n",
    "import FrEIA.modules as Fm\n",
    "import matplotlib\n",
    "\n",
    "from helpers import *\n",
    "from os.path import exists\n",
    "from argparse import ArgumentParser\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "plt.rcParams.update({'axes.labelsize': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--test'], dest='test', nargs=None, const=None, default=1, type=<class 'int'>, choices=None, help='Test run {True, False}', metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = ArgumentParser()\n",
    "parser.add_argument(\"-c\", \"--cuda\", dest=\"cuda\", default=1, type=int, help='Cuda number')\n",
    "\n",
    "parser.add_argument(\"-f\", '--flows', dest=\"flows\", default=8, type=int, help='Number of flows')\n",
    "parser.add_argument(\"--nn-hidden\", dest=\"nn_hidden\", default=3, type=int, help='Number of hidden layers for the NN')\n",
    "parser.add_argument(\"--nn-nodes\", dest=\"nn_nodes\", default=200, type=int, help='Number of hidden nodes for NN')\n",
    "parser.add_argument(\"--model\", dest=\"model\", default='8flows_3layer_200nodes_50000batch/model.pt', type=str, help='Path to model')\n",
    "parser.add_argument(\"--output\", dest=\"output\", default='flow_nnensemble_dummy/', type=str, help='Path for output files')\n",
    "\n",
    "parser.add_argument(\"--test\", dest=\"test\", default=0, type=int, help='Test run {True, False}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(cuda=1, flows=8, model='8flows_3layer_200nodes_50000batch/model.pt', nn_hidden=3, nn_nodes=200, output='flow_nnensemble_dummy/', test=1)\n"
     ]
    }
   ],
   "source": [
    "# pass default arguments if executed as ipynb\n",
    "try: \n",
    "    if get_ipython().__class__.__name__ == 'ZMQInteractiveShell': args = parser.parse_args(\"\") \n",
    "except:\n",
    "    args = parser.parse_args()\n",
    "\n",
    "device = torch.device(args.cuda)\n",
    "print(args)\n",
    "ensure_dir(args.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = ['metphi','pt_vis_c', 'phi_vis_c','pt_1', 'pt_2','dxy_1', 'dxy_2','dz_1',\n",
    "        'dz_2','eta_1', 'eta_2','mass_1', 'mass_2','metSumEt']\n",
    "names = ['uP1_uncorrected', 'uP2_uncorrected']\n",
    "paths = os.listdir('ensemble/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files from:  /ceph/lsowa/recoil/dt.root\n",
      "No.  1\n",
      "Reading files from:  /ceph/lsowa/recoil/mc.root\n",
      "No.  1\n"
     ]
    }
   ],
   "source": [
    "if exists('/ceph/lsowa/recoil/dt.root'):\n",
    "    dfdata = load_from_root('/ceph/lsowa/recoil/dt.root', test=args.test)\n",
    "    dfmc = load_from_root('/ceph/lsowa/recoil/mc.root', test=args.test)\n",
    "else:\n",
    "    # when running on cluster\n",
    "    dfdata = load_from_root('recoil/dt.root', test=args.test)\n",
    "    dfmc = load_from_root('recoil/mc.root', test=args.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dfdata[names].to_numpy().astype(float)\n",
    "mc = dfmc[names].to_numpy().astype(float)\n",
    "cdata = dfdata[cond].to_numpy().astype(float)\n",
    "cmc = dfmc[cond].to_numpy().astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +\n",
    "# Z standardize inputs\n",
    "# +\n",
    "input_scaler = StandardScaler()\n",
    "data = input_scaler.fit_transform(data)\n",
    "mc = input_scaler.transform(mc)\n",
    "\n",
    "cond_scaler = StandardScaler()\n",
    "cdata = cond_scaler.fit_transform(cdata)\n",
    "cmc = cond_scaler.transform(cmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, mc, cdata, cmc = torch.tensor(data), torch.tensor(mc), torch.tensor(cdata), torch.tensor(cmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pz = dist.MultivariateNormal(torch.zeros(2), torch.eye(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Load models\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlps\n",
    "mlps = []\n",
    "for path in paths:\n",
    "    with torch.no_grad():\n",
    "        mlp = Mlp(input_neurons=cdata.shape[1], hidden_neurons=200, output_neurons=2, hiddenlayers=3)\n",
    "        path = 'ensemble/' + path + '/model.pt'\n",
    "        mlp.load_state_dict(torch.load(path, map_location=\"cpu\"))\n",
    "        mlps.append(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flows\n",
    "def mlp_constructor(input_dim=2, out_dim=2, hidden_nodes=args.nn_nodes):\n",
    "    \n",
    "    layers = [nn.Linear(input_dim, hidden_nodes), nn.ReLU()]\n",
    "    for n in range(args.nn_hidden-1):\n",
    "        layers.append(nn.Linear(hidden_nodes, hidden_nodes))\n",
    "        layers.append(nn.ReLU())\n",
    "    layers.append(nn.Linear(hidden_nodes, out_dim))\n",
    "    \n",
    "    model = nn.Sequential(*layers)\n",
    "    return model\n",
    "\n",
    "model = Ff.SequenceINN(2)\n",
    "for k in range(args.flows):\n",
    "    model.append(Fm.RNVPCouplingBlock, subnet_constructor=mlp_constructor, \n",
    "                    clamp=2, cond=0, cond_shape=(cmc.shape[1],))\n",
    "\n",
    "model.load_state_dict(torch.load(args.model, map_location=\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# one event multiple times\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in range(100, 120):\n",
    "    csingle_event = cmc[event,:].unsqueeze(0)\n",
    "    csingle_events = torch.concat([csingle_event]*10000)\n",
    "\n",
    "    model.cpu()\n",
    "    z = pz.sample((csingle_events.shape[0], ))\n",
    "    u, _ = evaluate_sequential(model, z, cond=csingle_events.float(), rev=True)\n",
    "    u = input_scaler.inverse_transform(u)\n",
    "\n",
    "    u_mlps = []\n",
    "    for mlp in mlps:\n",
    "        with torch.no_grad():\n",
    "            out = mlp(csingle_event.float())\n",
    "            u_mlps.append(out)\n",
    "    u_mlps = torch.concat(u_mlps)\n",
    "    u_mlps = input_scaler.inverse_transform(u_mlps.numpy())\n",
    "\n",
    "    density_2d(u, u_mlps, \n",
    "        line_label=r'NN Ensemble NN($\\mathrm{cond}_\\mathrm{MC}$)=$\\vec{u}$', hist_label=r'model(z, $\\mathrm{cond}_\\mathrm{MC}$)=$\\vec{u}$',\n",
    "        crosses = [dfmc[\"uP1_uncorrected\"][event], dfmc[\"uP2_uncorrected\"][event]], crosses_label='$\\vec{u}^\\mathrm{truth}_\\mathrm{MC}$',\n",
    "        xlim = [-160, 100], ylim = [-80, 30], save_as=args.output+'fixedevent_flows_mlpensemble_eventid'+ str(event) +'.pdf', gridsize=(50,50), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# compare MLP ensemble with multiple evaluated NFlow\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptz = dfmc['pt_vis_c']\n",
    "cmc = cmc.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Mlp ensemble\n",
    "rs = []\n",
    "for mlp in mlps:\n",
    "    with torch.no_grad():\n",
    "        mlp.to(device)\n",
    "        out = mlp(cmc.float())\n",
    "        out = input_scaler.inverse_transform(out.cpu().numpy())\n",
    "        out = torch.tensor(out[:,0]) # keep u_perp\n",
    "    hist_raw, hist_weighted, bins, bin_mids = calc_response(uperp=out, ptz=ptz, cut_max=200, cut_min=25)\n",
    "    r = hist_weighted/hist_raw\n",
    "    rs.append(r)\n",
    "rs = np.array(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_downs, mlp_ups = np.percentile(rs, q=[2.5, 97.5], axis=0)\n",
    "mlp_means = np.mean(rs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate NFlow multiple times\n",
    "cmc = cmc.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-4fe216e669a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mu_flow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_sequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mu_flow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_flow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mhist_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist_weighted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbin_mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muperp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mu_flow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mptz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mptz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcut_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcut_min\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/lsowa/recoil_correction/helpers.py\u001b[0m in \u001b[0;36mevaluate_sequential\u001b[0;34m(model, data, cond, device, batch, rev)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ceph/lsowa/envs/cluster/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ceph/lsowa/envs/cluster/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ceph/lsowa/envs/cluster/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ceph/lsowa/envs/cluster/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pz = dist.MultivariateNormal(torch.zeros(2), torch.eye(2))\n",
    "rs_flow = []\n",
    "for i in range(len(mlps)):\n",
    "    z = pz.sample((cmc.shape[0], ))\n",
    "    u_flow, _ = evaluate_sequential(model, z, cond=cmc.float(), rev=True, device=device)\n",
    "    u_flow = input_scaler.inverse_transform(u_flow.cpu().numpy())\n",
    "    hist_raw, hist_weighted, bins, bin_mids = calc_response(uperp=u_flow[:,0], ptz=ptz, cut_max=200, cut_min=25)\n",
    "    r = hist_weighted/hist_raw\n",
    "    rs_flow.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_downs, flow_ups = np.percentile(rs_flow, q=[2.5, 97.5], axis=0)\n",
    "flow_means = np.mean(rs_flow, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mlp_means' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-b55fd5c148d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m plt.errorbar(x=bin_mids, y=mlp_means,\n\u001b[0m\u001b[1;32m      2\u001b[0m             xerr=(bins[1:]-bins[:-1])/2, yerr=[mlp_means-mlp_downs, mlp_ups-mlp_means], fmt='o', capsize=2, label='MLP Ensemble')\n\u001b[1;32m      3\u001b[0m plt.errorbar(x=bin_mids, y=flow_means,\n\u001b[1;32m      4\u001b[0m             xerr=(bins[1:]-bins[:-1])/2, yerr=[flow_means-flow_downs, flow_ups-flow_means], fmt='o', capsize=2, label='Flow')\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mlp_means' is not defined"
     ]
    }
   ],
   "source": [
    "plt.errorbar(x=bin_mids, y=mlp_means,\n",
    "            xerr=(bins[1:]-bins[:-1])/2, yerr=[mlp_means-mlp_downs, mlp_ups-mlp_means], fmt='o', capsize=2, label='MLP Ensemble')\n",
    "plt.errorbar(x=bin_mids, y=flow_means,\n",
    "            xerr=(bins[1:]-bins[:-1])/2, yerr=[flow_means-flow_downs, flow_ups-flow_means], fmt='o', capsize=2, label='Flow')\n",
    "\n",
    "plt.hlines([1], bins.min(), bins.max(), color='black')\n",
    "plt.xlabel(r'$p_\\mathrm{T}^Z$ in GeV')\n",
    "plt.ylabel(r'$\\langle \\frac{\\mathrm{u}_\\parallel}{p_\\mathrm{T}^Z}\\rangle$')\n",
    "plt.xlim([bins.min(), bins.max()])\n",
    "plt.legend()\n",
    "plt.savefig(args.output + 'response_compare.pdf')\n",
    "plt.clf()\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 ('cluster')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "51d79ee5a382be89a01a9124be8ffc10729a209d43e3ab0e2c741d5f20c6cac5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
